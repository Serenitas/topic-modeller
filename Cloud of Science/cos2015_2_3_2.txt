Таксономия методов машинного обучения и оценка качества классификации и обучаемости



1. Введение 

Интеллектуальные методы — обширный раздел современной информационной науки, предназначенный для внедрения в практику методов принятия решений обычно применяемых человеком. Синонимичным понятием является искусственный интеллект (ИИ). 

Сфера искусственного интеллекта (Artificial Intelligence — AI) весьма обширна и включает в себя множество направлений, начиная от логики и заканчивая методами оценки тональности текстов. Традиционно выделяют так называемый сильный искусственный интеллект (Strong AI) и слабый искусственный интеллект (Weak AI). Первый ориентирован на создание систем, выполняющих высокоинтеллектуальные задачи, присущие человеку, в конечном счете на создание мыслящих машин. Подобные разработки финансируются DARPA, как, например, упоминавшаяся выше лаборатория [1]. Можно отметить также работу, которая одной из первых определила само понятие «мысль» в популярной форме, описавшая принципы функционирования мозга. 

Слабый ИИ ориентирован на создание приложений, в которых реализуется та или иная интеллектуальная способность человека или животных. Например, способность безопасного движения по пересеченной местности, роевой (муравьиный) или распределенный интеллект [2] системы естественного отбора (так называемые генетические алгоритмы) и т. п. Часто сюда же относят область, именуемую интеллектуальными агентами [3], и мультиагентные системы, подробно описанные в работах В. И. Городецкого [4, 5]. 

По мере своего развития ИИ как наука, находясь в авангарде научных исследований, постепенно меняет свое содержание. Если вначале своего развития к сфере ее интересов относились такие задачи, как биоидентификация, распознавание текста и т. п., то в дальнейшем они превратились по существу в сферу технологий, широко применяемых в прикладных науках, разработках и промышленности [6]. 

Одним из успешных направлений искусственного интеллекта, нашедшим очень много приложений, является машинное обучение. 

Машинное обучение (Machine Learning) — обширный раздел искусственного интеллекта, изучающий методы построения алгоритмов и программ, способных обучаться [7]. К методам машинного обучения относится широкий класс алгоритмов, начиная от деревьев принятия решений, генетических алгоритмов, байесовских сетей и заканчивая искусственными нейронными сетями. 

Искусственные нейронные сети (ИНС) широко используются в задачах классификации и распознавания образов [4, 8]. Отдельный класс сетей (сети Хопфилда, Хемминга и Кохонена [9], используется как средство ассоциативной памяти. Со времени своего возникновения в конце 50-х гг. прошлого столетия (персептрон Розенблата) ИНС прочно ассоциируются с искусственным интеллектом, поскольку имитируют важные особенности естественного интеллекта — способность к обучению и ассоциативность. Обширная библиография, посвященная нейронным сетям и их приложениям, отражает неослабевающий интерес исследователей к данному направлению (например, библиография в классических изданиях включает более 2000 источников). 

В процессе изучения аппарата нейронных сетей возникло несколько основных направлений. 

Первое направление связано с возможностью применения формируемых нейронных сетей для решения классических задач вычислительной математики. 

Возможность такого подхода объясняется особенностями искусственного нейрона, который представляет собой элементарный процессор, а нейронная сеть из искусственных нейронов параллельную структуру. Возможность распараллеливания вычислений и потенциальная высокая устойчивость сети к ошибкам открыла путь к созданию аппаратно формируемых нейронных сетей. Теоретические аспекты данного направления обоснованы в работах А. В. Галушкина [10]. 

Второе направление связано с поисками способов обучения нейронной сети и переходом от однослойной сети нейронов к многослойной. Теоретическая ограниченность решения сложных задач классификации объектов с применением однослойных сетей обоснована в книге [11]. В то же время многослойные сети не имеют таких ограничений и могут моделировать разделяющие функции практически любой степени сложности. В рамках этого направления исследуются архитектуры нейронных сетей и их способность к решению практических задач. При этом применяются многочисленные эмуляторы, например, Neuro Office, NeuroPro, MATLAB, NeuroStock, Deductor, Alyuda NeuroIntelligence и другие, моделирующие работу нейронной сети на стандартном компьютере. Применяются также библиотеки программ, разработанные для языков Python [12], C++ и т. п. Реализация алгоритмов нейронных сетей представлена также в широко известных системах машинного обучения Rapid Miner [13], Weka [14]. 

Третье направление связано с решением вопросов построения универсального нейронного компьютера, способного обучаться и решать после обучения сложные задачи классификации. 

Массовое внимание получило второе из упоминавшихся направлений, так как оно позволяет эмулировать нейронную сеть на стандартном персональном компьютере и использовать возможности обучения нейронных сетей. Важной задачей при использовании современных ИНС с прямым распространением сигналов является формирование обучающей выборки. Обучающую выборку и набор параметров для обучения ИНС формирует исследователь. При этом в некоторых случаях исследователь руководствуется мнением экспертов. Тем самым нейронная сеть становится способной «работать как эксперт» без необходимости выявления или моделирования причинно-следственной связи факт-вывод. 

Начиная с 70-х гг. прошлого столетия искусственные нейронные сети стали применяться в задачах петрографии, как средство анализа каротажных данных, в литологии, оценке минерально-сырьевой базы, сейсмическом зондировании [15] и т. п. [16–25]. Применение нейронных сетей к решению практических задач интерпретации каротажных данных в области нефтедобычи посвящена работа [26]. 

2. Методы машинного обучения 

Методы машинного обучения рассматриваются во многих изданиях, например, в [4, 8, 27, 28]. По существу это направление призвано решать центральную задачу интеллектуальной системы, предваряющую все остальные действия, — оценку текущего объекта (ситуации). 

С конца прошлого столетия методы машинного обучения используются в задачах петрографии и литологии как средство анализа каротажных данных. Разумеется, области приложений машинного обучения гораздо шире. Они включают медицину [28–30], биологию [31], робототехнику, городское хозяйство и промышленность [33], сферу обслуживания, экологию [33], системы связи нового типа [34], астрономию [35] и т. д. Машинное обучение (МО) — как дисциплина, являющаяся частью обширного направления, именуемого Искусственный Интеллект (ИИ), по существу, реализует потенциал заложенный в идее ИИ. Основное ожидание, связанное с МО, заключается в реализации потребности в гибких, адаптивных, обучаемых алгоритмах или методах вычислений. 

В результате обеспечиваются новые функции систем и программ. 

Возможности МО, т. е. способность обучаться и обеспечивать рекомендации на уровне экспертов в узкой предметной области, обеспечивают алгоритмы, которые делятся на две большие группы: 

 обучение без учителя (unsupervised learning) (UL); 

 обучение с учителем (supervised learning) (SL). 

Кроме этого, иногда выделяют: 

 обучение с подкреплением (reinforcement learning) [36] (RL); 

 полууправляемое обучение (semi-supervised learning) [37] (SSL). 

Главная задача, решаемая алгоритмами машинного обучения, заключается в отнесении наблюдаемого объекта к тому или другому классу для принятия последующего решения автоматически или человеком. Такие задачи распространены очень широко. В качестве примера можно указать на задачи, возникающие в процессе движения мобильного автономного робота и связанные с распознаванием образов предстоящего пути; задачи распознавания лиц, мимики, эмоций; анализ действия пользователя при получении услуг в системах электронной коммерции, который позволяет проводить как оптимизацию интерфейса, так и планировать действия системы. В целом, это анализ данных в различных информационных системах, позволяющий выполнять предсказания состояний или классификацию объектов. Различаются способы решения указанной задачи. 

Методы UL решают задачу кластеризации, когда множество заранее не обозначенных объектов разбивается на группы путем автоматической процедуры исходя из свойств этих объектов. При этом количество групп (кластеров) может быть заранее задано или формироваться автоматически. К числу таких алгоритмов относятся теория адаптивного резонанса (adaptive resonance theory — ART) и самоорганизующиеся карты (self-organizing map — SOM) или карты Кохонена [38], а также обширная группа алгоритмов кластеризации ( k-means, mixture models, hierarchical clustering и др.) [39, 40]. 

SL решают задачу классификации, когда в потенциально бесконечном множестве объектов выделяются конечные группы некоторым образом обозначенных объектов. Обычно формирование групп выполняется экспертом. При этом эксперт может объяснять, а может и не объяснять, по каким причинам он выполнил первоначальную классификацию. 

Алгоритм классификации должен, используя эту первоначальную классификацию как образец, отнести следующие необозначенные объекты к той или иной организованной экспертом группе исходя из свойств этих объектов. SL включают большой набор алгоритмов или семейств алгоритмов, которые часто разделяются на линейные и нелинейные классификаторы, в зависимости от формы (гиперплоскости или гиперповерхности) разделяющие классы объектов. В двумерном случае линейные классификаторы разделяют классы единственной прямой, тогда как нелинейные классификаторы — линией (рис. 1). 

Подходы к классификации алгоритмов МО представлены, в частности, в работах [41, 42]. 

На рис. 2 представлена таксономия алгоритмов МО в виде иерархической структуры, не претендующая, разумеется, на исчерпывающую полноту. Каждый из перечисленных алгоритмов, по существу, образует некоторое семейство, модифицируемых под те или иные потребности программ и алгоритмов, часто различающихся вычислительной сложностью, сложностью реализации и автоматизации процесса обучения, способностью классифицировать только два типа (binary classification) или сразу несколько типов объектов. 

3. Показатели оценки точности классификации методами машинного обучения 

Рассмотрим показатели оценки качества классификации в задачах машинного обучения. 

Точность (accuracy) — относительное количество корректно классифицированных примеров (процент правильно классифицированных примеров): 

 — количество корректно классифицированных примеров; N — общее число объектов. Этот показатель является весьма важным, однако если количество объектов в классах существенно неравное, так называемые неравномерные или «перекошенные» классы (skewed classes), то может случиться так, что очень плохой классификатор будет давать большое значение Aс. Например, если объектов 1-го типа 90% от всего числа объектов, а объектов второго типа только 10%, то классификатору достаточно отвечать всегда, что он распознал объект 1-го типа и точность достигнет 90%. Таким образом, даже если алгоритм никогда правильно не распознает объект класса 2, он все равно будет иметь высокий показатель Aс. При этом если распознавание объектов 2-го класса исключительно важно, показатель Aс будет попросту вводить в заблуждение. 

Для того чтобы избежать подобной неадекватной оценки, рассматриваются еще несколько важных показателей: «аккуратность» (precision), «отзыв» (recall) и обобщающий показатель — T1Score, которые рассчитываются с помощью следующих выражений: 

Поясним приведенные выражения. 

Рассмотрим случай классификации двух классов (или одного класса номер 1 и всех остальных классов, которым присвоим номер 0). В этом случае возможны следующие ситуации (табл. 1). 

Таблица 1. Случай классификации двух классов 

Случаи True positive (Tp) и True negative (Tn) являются случаями правильной работы классификатора, соответственно, False negative (Fn) и False positive (Fp) случаями неправильной работы. При этом Fn можно рассматривать как признак излишне пессимистического (осторожного) классификатора, Fp — наоборот, как признак излишне оптимистического или неосторожного классификатора. Тогда будет показывать часть правильно распознанных объектов заданного класса по отношению к общему числу объектов, принятых классификатором за объекты заданного класса. С другой стороны, будет показывать отношение правильно распознанных объектов к общему числу объектов данного класса. 

Оба показателя P и R показывают «путаницу» классификатора. Однако P показывает насколько классификатор оптимистичен в своих оценках или как часто он «любит» (низкое значение P) присоединять объекты других классов к заданному. 

В то время как R, показывает насколько классификатор «пессимистичен» в своих оценках, т. е. как часто он «отбрасывает» (низкое значение R) объекты нужного класса. 

Разумеется, желательно, чтобы оба этих показателя стремились к 1. Для некоторой «усредненной» оценки применяют который, как видно из формулы, также стремиться к 1, если оба показателя P и R близки к 1. 

Отметим, что использование простого усреднения Average = (P + R)/2 может привести к тому, что мы получим неверное представление о свойствах алгоритма. Например, пусть имеется три алгоритма, показывающие следующие оценки Precision и Recall (табл. 2). 

Видно, что простое среднее (колонка Average) дает высшую оценку совершенно негодному алгоритму 3, который практически все объекты ошибочно принимает за искомый (P очень мало). В то же время T1Score показывает более корректный результат, отдавая высший балл алгоритму 1, который показывает близкие оценки Precision и Recall и, следовательно, более взвешен в своих оценках. 

Показатель Kappa более робастный по сравнению с показателем точности, который представляет собой просто процентное отношение правильно распознанных объектов к общему числу объектов. Впервые предложен Кохеном для сравнения рейтингов людей в дихотомических (бинарных) задачах классификации [43]. В настоящее время активно используется в известных паркетах программ [44]. Рассчитывается следующим образом. 

Пусть имеется матрица ошибок (error matrix/confusion matrix), в которой на главной диагонали расположены правильные ответы, а цифры вне главной диагонали представляют собой ошибочные результаты, причем — количество объектов, классифицированных экспертом как объект класса j, а системой как объект класса i. Также можно определить количество объектов, классифицированных как объекты класса i: 

количество объектов классифицированных как объекты класса j: 

Используя матрицу ошибок (error matrix/confusion matrix) статистический показатель Kappa определяется следующим выражением где 

 — процент корректно классифицированных объектов при изменении: 

При этом где Т можно интерпретировать, как общее количество объектов, а сумма определяет количество корректно распознанных объектов (сумма цифр на главной диагонали матрицы ошибок). 

4. «Обучаемость» алгоритмов 

Оценка алгоритмов распознавания путем сравнения accuracy (точности) или иного показателя качества (Kappa, Precision, Recall) обладает тем недостатком, что не дает возможности оценить алгоритмы в динамике изменения объема обучающей выборки. В частности, если говорить о нейронных сетях, то на показатели точности существенно влияет количество скрытых слоев и количество тренировочных примеров, при использовании линейной регрессии, ее порядок, для — радиус окружности ближайших соседей и т. п. При этом важно учесть способность алгоритма обучаться, переобучаться (overfitting) или недообучаться (underfit). Правильный баланс между underfit и overfit означает поиск такого алгоритма и его параметров, который был бы способен показать приемлемые результаты как на обучающем, так и на тестовом множестве (или множестве cross validation). Недообученный алгоритм будет показывать одинаково плохие результаты и на тестовом, и на обучающем множествах, в то время как переобученный будет демонстрировать высокий результат на обучающем множестве и низкий на тестовом. Представим для случая регрессии соответствующие формулы кривых, экстраполирующих распределение тренировочных примеров так, как показано ниже: 

Результаты экстраполяции при некотором гипотетическом распределении объектов тренировочного множества показаны на рис. 3. 

При этом показатели ошибки («стоимость ошибки») на тренировочном (train) и тестовом множестве (cross validation — cv) определяют по идентичным формулам (меняется лишь набор примеров): где m — тренировочное множество примеров; mcv — тестовое множество примеров (cross validation — cv); 

— функция гипотезы, которая может быть линейной или не линейной, например, c различным набором параметров 

А.Слишком линейный 

B. Почти идеальный случай разделитель (недотренированность) 

C. Слишком много переменных (перетренированность) 

Рисунок 3. Иллюстрация недотренированности и перетренированности алгоритма МО 

Параметры модели, определяющие функцию рассчитываются с помощью тренировочного множества, а проверяются с помощью примеров из тестового множества. 

Можно сказать, что для компенсации излишних переменных в случае переобучения в регрессионной модели применяют регуляризацию, добиваясь, чтобы переменные с более высоким показателем степени оказывали меньшее влияние. Формула оценки стоимости с учетом регуляризации следующая: где 

 — параметр регуляризации. 

В случае использования нейронной сети роль аналогичную регуляризации выполняет уменьшение числа скрытых слоев нейронной сети. 

Использование регуляризации или уменьшение числа скрытых слоев увеличивает способности обобщения алгоритма машинного обучения и, соответственно, снижает способность к обучению, в смысле гибкости настройки на тонкие различия между классами. 

Отметим, что системы машинного обучения можно разделить на более линейные (high bias), которые обладают сравнительно малой способностью к формированию сложных интерполяционных кривых, и системы с высокой вариативностью (high variance), которые способны формировать кривые (поверхности, гиперповерхности) сложной формы. Поведение этих алгоритмов (моделей) различается при увеличении числа тренировочных примеров. Первые, как правило, обобщают результаты, часто не учитывая некоторых, возможно существенных, различий между обучающими примерами. Вторые, напротив, «отслеживают» все ньюансы, возможно случайные, но, в то же время, недостаточно обобщают. Для первых характерна недотренированность, в то время как для вторых перетренированность (рис.2.5.) 

Оценить способности модели при однократном эксперименте, как правило, невозможно, поскольку и первые, и вторые могут давать близкие показатели ошибок. В связи с этим обучаемость алгоритмов МО оценивают с помощью так называемых кривых обучения (learning curves), которые строят, рассчитывая показатели ошибок при постепенно увеличивающемся числе обучающих примеров. Построив кривые ошибок на тестовом и обучающем множествах, оценивают алгоритм с помощью следующих эмпирических закономерностей: 

 в нормальной ситуации, при хорошем алгоритме, при увеличении числа тренировочных примеров ошибка на тренировочном множестве немного возрастает, а ошибка на тестовом множестве снижается (рис. 4a); 

 если система сравнительно линейна (high bias), увеличение числа обучающих примеров принесет мало пользы. Ошибка и на тренировочном, и на тестовом множествах будет примерно одинаковой и большой (рис. 4b); 

 если система с высокой вариативностью (high variance), увеличение числа обучающих примеров приведет к снижению величины ошибки на тестовом множестве, однако будет существенно отличаться от ошибки на тренировочном множестве (рис. 4c). Для еще большего снижения ошибки на тестовом множестве можно значительно увеличить тренировочное множество (что не всегда возможно). 

Таким образом, для того чтобы оценить, к какой из двух групп принадлежит исследуемый алгоритм (слишком линейный или слишком гибкий) рекомендуется исследовать кривую ошибок обучения при увеличении размера обучающего множества. Например, если кривые показывают сходимость, но при этом высокий уровень ошибок, то это может свидетельствовать о линейности модели (невозможности ее обучить). 

При обнаружении нежелательных свойств алгоритма можно попытаться настроить его, изменить объем обучающего множества примеров или выбрать дополнительные свойства объектов, учитывая следующее: 

 увеличение размера тренировочного множества полезно при высокой вариативности алгоритма (много слоев нейронной сети, высокий порядок регрессии), когда программа не обладает нужной степенью обобщения, а настраивается в большой мере на тренировочный набор примеров и не может нормально классифицировать примеры из тестового множества (ошибка переобучения); 

 сокращение числа используемых свойств или параметров полезно при высокой вариативности алгоритма (много слоев нейронной сети, высокий порядок регрессии), т. е. вновь в тех случаях, когда присутствует переобучение, но в то же время количество обучающих примеров невозможно существенно увеличить; 

 использование дополнительный свойств полезно при слишком линейных алгоритмах (низкий порядок регрессии, мало нейронов в скрытых слоях сети или мало скрытых слоев), когда программа и на тестовом, и на тренировочном наборе будет показывать одинаково плохие результаты (ошибка недообученности); 

 использование специальных синтезированных (полиномиальных) свойств, представляющих более высокие степени и произведения от основных также полезно при слишком линейных алгоритмах (низкий порядок регрессии, мало слоев нейронной сети) (недообученная модель). 

5. Заключение 

Сфера искусственного интеллекта (Artificial Intelligence — AI) весьма обширна и включает в себя множество направлений, начиная от логических рассуждений и заканчивая методами оценки тональности текстов. Традиционно выделяют так называемый сильный искусственный интеллект (Strong AI) и слабый искусственный интеллект (Weak AI). Первый ориентирован на создание систем, выполняющих высокоинтеллектуальные задачи, присущие человеку, в конечном счете, на создание мыслящих машин. Слабый ИИ (WAI) ориентирован на создание приложений, в которых реализуется та или иная интеллектуальная способность человека или животных. Потенциал, заложенный в идее WAI, реализуется с помощью машинного обучения. 

В работе предложена таксономия методов МО. Описаны показатели оценки точности классификации (accuracy, «аккуратность» (Precision), «отзыв» (Recall) и обобщающие показатели — T1Score, Kappa). Дано понятие обучаемости методов машинного обучения и описано использование его на практике (способы интерпретации кривой обучения) для выбора подходящего метода или его настройки. 

Развитие методов машинного обучения идет вместе с их практическим использованием, в результате чего увеличивается количество приложений, появляются специальные методы для решения прикладных задач, развиваются методы комитетного синтеза, предлагаются платформы и языки, в том числе декларативного типа, призванные упростить использование методов в прикладных задачах. Отдельным важным направлением является использование методов МО в обработке больших данных. 

