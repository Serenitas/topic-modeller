Основные концепции и результаты робастной оптимизации в применении к линейному программированию с неточными данными 

В приложениях оптимизации «настоящие» численные данные задачи, которую должен решить пользователь, в момент решения задачи, как правило, известны лишь приближенно. Традиционно небольшие (измеряемые долями процента) неточности в данных просто игнорируются, и задача решается при номинальных данных (доступных пользователю оценках фактических данных),  в надежде, что при  небольших расхождениях между фактическими и номинальными данными оптимальное решение, построенное по номинальным данным («номинальное оптимальное решение»),  окажется достаточно хорошим и при фактических данных. Оказывается, однако, что часто совсем небольшие расхождения между фактическими и номинальными данными приводят к тому, что номинальное решение при переходе от номинальных к фактическим данным начинает сильно нарушать ограничения задачи и тем самым становится практически бесполезным. Подобный эффект наблюдался, например, при тестировании задач линейного программирования из библиотеки NETLIB; в 13 из 90 протестированных задач возмущения «явно неточных» коэффициентов (вроде 0.946049 — трудно поверить, что в реальной жизни коэффициент такого вида можно  и в самом деле оценить с 6 знаками точности) всего на 0.01% приводили к тому, что номинальное решение, при подстановке в задачу фактических данных, нарушало некоторые ограничения на более чем 50% от их правых частей; в одном из примеров (PILOT4, 411 ограничений на 1000 переменных) нарушения достигали 210 000% (!) от правых частей. 

Таким образом, практические применения оптимизации нуждаются в методологии, способной заранее учесть неточность данных и получать «иммунизированные» к этим неточностям решения. Исторически единственной методологией такого рода было стохастическое программирование, предполагающее неточно известные данные случайными величинами с известным совместным распределением и требующие от допустимого решения удовлетворять ограничениям задачи (левые части которых становятся теперь случайными величинами с распределениями, зависящими, как от параметра, от подставляемого решения)  с заданной и близкой к 1 вероятностью. Такой подход страдает от двух недостатков. 

Во-первых, если в реальности «настоящие данные» и в самом деле выбираются по некоторому распределению (что не всегда так), идентифицировать это распределение обычно весьма трудно. 

Во-вторых, стохастические формулировки оптимизационных задач, даже таких простых, как задачи линейного программирования, оказываются чрезвычайно трудоемкими в вычислительном отношении,  не допускающими гарантированного отыскания приближенного решения высокой точности за разумное время. 

Робастная оптимизация (РО) — это сформировавшаяся и ставшая популярной за последние две декады альтернативная к стохастическому программированию методология иммунизации решений оптимизационных задач к неопределенности в данных1. В РО данные считаются меняющимися в заданной области неопределенности, а от решений требуется робастная допустимость — требуется, чтобы они оставались допустимыми при всех наборах данных из указанного множества неопределенности. Предполагая (что на самом деле не ограничивает общности), что данные, входящие в целевой функционал, известны точно, РО рекомендует использовать наилучшие по целевому функционалу среди робастно допустимых решений. 

Оказывается, что оптимальное робастное решение во многих случаях можно найти эффективно. Это так, например, в задачах линейного программирования, в предположении, что множество неопределенности (которое  становится теперь множеством в многомерном пространстве наборов коэффициентов матрицы ограничений, целевого функционала и правых частей ограничений) задано конечным числом линейных неравенств. В этом случае отыскание оптимального робастного решения сводится к решению явно выписываемой задачи обычного линейного программирования с размерами, сравнимыми с размерами исходной задачи плюс размеры описания множества неопределенности. 

