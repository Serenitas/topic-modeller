
Основным показателем производительности вычислительной системы является производительность микропроцессора.
Д.
Паттерсон и Дж.
Хеннесси [1] определили производительность микропроцессора как Как видим, производительность зависит от трех характеристик: частоты, частоты на инструкцию и количества инструкций.
Более того, время работы процессора  в равной степени зависит от каждой из них: увеличение на 10 % одной дает общий прирост тоже в 10 %.
К сожалению, сложно изменить один из этих параметров отдельно от остальных, поскольку основные технологии, определяющие каждую характеристику, взаимозависимые: частота определяется технологией изготовления микропроцессора, частота на инструкцию архитектурой микропроцессора, количество инструкций системой команд и технологией компиляции.
Улучшение технологических норм изготовления кристаллов микросхем и увеличение числа транзисторов в микросхемах примерно до 2003 г.тоже вызывало постоянный рост частоты микропроцессоров вплоть до 34 ГГц.
Однако дальнейшее повышение частоты обусловило существенное повышение потребления питания и, соответственно, повышение тепловыделения, которое невозможно отвести от кристаллов стандартными средствами [2].
Повышение производительности стало достигаться за счет усложнения архитектуры ядра микропроцессора, включения дополнительных функций, сопроцессоров и, главное, за счет создания многоядерных микропроцессоров и многопроцессорных систем [2].
В связи с этим на первый план стала выдвигаться задача создания высокоэффективной коммуникационной среды.
Одной из наиболее перспективных сред является коммуникационная среда RapidIO .
Стандарт RIO разрабатывался специально для удовлетворения важнейших требований приложений реального времени: обеспечения малых задержек, детерминизма, надежности и масштабируемости, снижения энергопотребления, размеров и веса, обусловленного требованиями встроенных систем.
Высокие показатели по скорости передачи и надежности привели к тому, что RIO начинает использоваться и для построения серверов, прежде всего серверов с плотной упаковкой.
Кроме того, стандарт RIO позволяет унифицировать коммуникационную среду на модульном, межмодульном и межмашинном уровнях [3], что существенно удешевляет систему и упрощает ПО.
Для дальнейшей унификации и снижения затрат на разработку предложен блок  перехода с внутрипроцессорной шины AXI на внешнюю шинуRIOпозволяющий создавать как многоядерные процессоры, так и коммутаторы с коммуникационной средой RIO.
К процессорному ядру подключено .
На рисунке 2 приведена структурная схема блока межпроцессорного обмена.
Схема состоит из следующих основных блоков: порты RIO, блок коммутации RIO и блок преобразования пакета RIO в пакет AXI.
Блок преобразования состоит из блоков приема запроса и выдачи ответа RIO, коммутатора запросов, блока регистров, контроллера шины AXI и еще трех контроллеров: контроллера дверных замков, почтовых ящиков  и транзакций ввода-вывода RIO.
Во время работы внешнее обращение поступает в порт RIO, далее пакет в зависимости от настроек таблицы маршрутизации передается в один из выходных портов.
При обращении к процессору  пакет RIO преобразуется в пакет AXI и затем поступает в процессор.
С точки зрения программной модели, внутри микросхемы находится одно RIO-устройство.
Рассмотрим характеристики, свойства и трудозатраты на реализацию блока межпроцессорного обмена для двух процессоров.
Наиболее очевидными являются два варианта исполнения этого блока: подключение к одному порту RIO с использованием коммутатора AXI; подключение к порту RIO с созданием виртуальных каналов.
Первый вариант предполагает структуру, изображенную на рисунке 4.
Рассмотрим затраты на разработку аппаратной части.
Для реализации этой схемы необходимо разработать коммутатор AXI.
Далее при работе с одним портом RIO нужно разделить пакеты между двумя процессорами.
Это можно реализовать через разделение адресного пространства, через контроллер сообщений или тип пакета.
Для такого разделения необходимо значительно изменить контроллер сообщений.
На изменение программной части требуется значительное изменение работы с разделением адресного пространства с двумя процессорами, находящимися на одном порту RIO.
К достоинствам такого подхода можно отнести отсутствие дублирования контроллеров, к недостаткам появление дополнительной задержки при прохождении пакета через AXI-коммутатор по сравнению со схемой, по которой происходит взаимодействие с одним ядром.
Для реализации второго способа соединения процессоров необходимо сделать следующие изменения аппаратной части: подключить блок регистров к блоку коммутации, незначительно изменить структуру блока регистров AXI, подключить второй блок преобразования пакета RIO в пакет AXI.
В программной модели обозначенная структура будет определена как три устройства RIO, с каждым из которых можно работать независимо от другого: коммутатор RIO, блок RIO-AXI 1, блок RIO-AXI 2.
При таком соединении соблюдается преемственность кода, все имеющиеся наработки с внесением незначительных изменений можно применить к новому блоку.
Недостаток состоит в дублировании внутреннего содержания блока преобразования пакета RIO в AXI, достоинство в сохранении задержки передачи на том же уровне, что и в унифицированном блоке с одним процессором.
Как видим, реализация второго варианта не только менее трудозатратна, но и обладает меньшими задержками при передаче пакета, являющимися одним из основных параметров таких систем.
Таким образом, при относительно небольшом числе ядер данное решение оптимально.
Принятие разработчиком решения должно основываться на оптимизации трудоемкости проекта, производительности, потребляемой мощности и числе транзисторов  для данных вариантов.
С учетом этих параметров выбран второй вариант.
Рассмотрим выбранную схему соединения процессоров.
Схема состоит из трех блоков.
Первый блок это 8-портовый коммутатор, к которому подсоединен 1 порт PRIO, 4 порта SRIO, блок регистров и 2 виртуальных порта RIO.
К первому виртуальному порту подключен блок RIO-AXI 1, который состоит из коммутатора запросов AXI, блока приема запросов и выдачи ответов RIO, блока регистров и трех контроллеров: дверных замков, почтовых ящиков и транзакций ввода-вывода RIO.
Блок RIO-AXI 2 полностью аналогичен блоку RIO-AXI 1.
Опишем процесс передачи сообщения между процессорами, находящимися на одном кристалле.
Примем, что таблица маршрутизации сконфигурирована.
В начале передачи первый процессор, подключенный по AXI к блоку RIO-AXI 1, заполняет поля в блоке регистров.
Во время этой операции в блок регистров AXI пишутся адрес, данные, тип пакета, возможное число переходов и другие служебные поля.
После этого пакет поступает в блок преобразования из интерфейса AXI в интерфейс локальной шины.
Затем пакет поступает в блок преобразования из локальной шины в интерфейс RIO блок выдачи ответов RIO.
После этой передачи пакет поступает на виртуальный канал RIO, а затем в 5-й порт коммутатора и передается в 6-й в соответствии с таблицей маршрутизации.
После появления пакета на 6-м порту коммутатора описанная операция выполняется в обратном порядке, за исключением передачи данных из виртуального канала в блок приема ответов RIO и выхода пакета из блока RIO-AXI 2 на интерфейс AXI ко второму процессору.
В случае передачи на соседний кристалл операция аналогична описанной, за исключением конфигурации таблицы маршрутизации.
Коммутатор относится к классу коммутаторов со входной буферизацией [4] .
Он может работать в двух режимах: приоритетной передачи пакетов и циклическом [5] .
Если коммутатор работает в режиме приоритетной передачи и несколько входных портов передают пакет в один выходной, то первым передается наиболее приоритетный пакет.
Пакеты с равным приоритетом передаются в циклическом режиме.
Поскольку рассматриваемый коммутатор относится к классу коммутаторов со входной буферизацией, существует проблема блокировки головного пакета  [6].
Она решена путем перемещения блокирующего пакета на случайное место в очереди.
При этом перемещении выполняется также перемещение более приоритетных пакетов в начало очереди.
Данная архитектура коммутатора является оптимальной благодаря простоте реализации и хорошим временным характеристикам, а именно, низкой задержке прохождения пакета и, как следствие, низким аппаратным затратам.
Недостатком такого решения является отсутствие алгоритма, находящего максимальные паросочетания  [7], из-за чего выходные порты ядра коммутатора могут простаивать, понижая максимальную пропускную способность в случае неравномерного распределения номера порта назначения и длины пакетов.
Рассмотрим достоинства созданного IP-блока.
Основной механизм передача сообщений между процессорами.
Низкая задержка передачи пакета.
Масштабируемость.
Возможно соединение 5 кристаллов без дополнительных элементов.
Chip означает отдельный кристалл, CPU ядро одного процессора, SwitchIP ядро RIOAXI.
При помощи дополнительных коммутаторов возможно соединение до 256 процессоров.
Возможно соединение и более сложных многоядерных схем, например тороидальной сети.
Совместимость с имеющимся ПО.
Имеющиеся наработки ПО совместимы с этим IP-ядром, сохраняется модель контроллера передачи сообщений .
Однородность доступа к процессору на одном и нескольких кристаллах.
Для программиста обращение к процессору на одном кристалле выглядит так же, как и обращение к другому кристаллу.
Дублирующий режим.
В некоторых надежных системах существует требование выполнения операций процессорами в дублирующем режиме.
Использование разработанного ядра позволяет поддерживать этот режим.
Возможность дальнейшего развития.
При необходимости блок можно расширить, увеличив количество портов коммутатора.
В результате увеличивается количество периферийных портов или виртуальных каналов RIO для подключения процессоров.
Программные наработки при этом также сохраняются.
После сборки и отладки проекта были проведены исследования временных параметров измерение задержки при передаче пакетов от одного процессора к другому.
Измерения задержки были выполнены на модели и составили порядка 400 нс.
Полученные значения говорят о низкой задержке передачи пакета.
С учетом поправки на рабочую тактовую частоту эта задержка сопоставима с задержкой, полученной авторами при тестировании многопроцессорного взаимодействия [9].
Таким образом, в результате проделанной работы определены возможные варианты создания унифицированных блоков каналов RIO, проведена оптимизация и разработан блок, обеспечивающий высокую производительность различных многопроцессорных систем.
Modern multiprocessor systems are usually based on the communication environment.
The most popular high-performance network environments are: HyperTransport, PCI Express, ASI, RapidIO, VXS, StarFabric, 10GB Ethernet, InfiniBand, Myrinet.
A communication environment is created on chip level, module level, inter-module level and inter-machine level.
The RapidIO standard is focused on creating the last three environments and thus we can unify a multiprocessor system.
For further unification we need to develop the module of the exchange between the microprocessors core and the external environment in order to improve the reliability and reduce labor effort.
The article discusses a unified adapter block  for a transition from on-chip AXI bus to the external RapidIO bus to create as multicore processors as well as switches with RapidIO environment.
Chip production technology improvement and increase in the number of transistors in the chips until 2003 has led to permanent growth of microprocessor frequency up to 34 GHz.
However, further increase in frequency has caused a substantial increase of power consumption and heat dissipation, which is impossible to withdraw from crystals using standard means.
Increased productivity has been achieved by expenses on complicated architecture of microprocessor cores, additional functions, coprocessors and, most importantly, by creating multi-core microprocessors and multiprocessor systems.
Therefore, a high-performance communication environment is emphasized.
RapidIO communication environment is one of the most promising.
The RapidIO standard is designed specifically to meet critical requirements of real-time applications, which are: low latency, determinism, reliability and scalability, reduction of power consumption, size and weight.
Bobkov S.G.
[High-Performance Computer Systems].
Promising industrial high-performance computer systems based on RapidIO standard.
[Proc.
of the 11th Russian Science and Tech.
Conf.
Electronics, microi nanoelectronics].
1999, vol.
47, no.
8, pp.
12601267.
r.
1999, pp.
789798.
Erzin A.I.
[Introduction to Operation Analysis].
Study guide, Novosobirsk, Novosibirsk State Univ.
Olenev N.N.
[The Basics of parallel programming in MPI].
Devashish P..
2015, April 1416, 2015, p.
4.
1.
2015.
4 .
С.
8892.
2.
2015; -235X.112.088-092.
3.
High performance RapidIO block to create multi-core microprocessors with RapidIO virtual links.
2015, no.
