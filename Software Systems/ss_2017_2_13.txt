
Ньютоновские методы фундаментальные инструменты численного анализа, исследования операций оптимизации и управления.
Например, большинство наиболее известных методов в линейном и нелинейном программировании строятся на их основе.
Общий принцип построения большинства ньютоновских методов опишем следующим образом.
Рассмотрим задачу безусловной минимизации min,  где : гладкая функция;пространство.
Пусть, градиент и гессиан, вычисленные на итерации в точке процесса решения задачи .
Тогда общий принцип построения большинства ньютоновских методов безусловной оптимизации с регулировкой шага состоит в следующем.
При этом процедуру построения организуют так, чтобы совпадала с исходной матрицей, если последняя сама является положительно определенной, причем выяснение определенности и построение осуществляются параллельно в рамках одной процедуры на основе некоторых матричных разложений, которые позволяют выявить знаки собственных чисел и приспособиться для генерации.
На практике условие гладкости целевой функции является излишне строгим: как правило, или первые и  вторые производные не существуют, или процесс вычисления этих производных слишком трудоемок.
В этом случае быстро сходящийся алгоритм можно построить на основе их конечно-разностной аппроксимации.
Подобно своему классическому прототипу он порождает целый класс модифицированных методов, причем модификации, предлагаемые для обобщения метода Ньютона на случаи со знаконеопределенными, применимы и к его конечно-разностному аналогу, и наоборот [1, 2].
В данной работе в основе выяснения определенности и построения лежит факторизация  Холесского.
Поскольку столбцы матрицы с номерами с 1-го по -й известны, ее.
Аналогичные формулы существуют и для построчной организации вычислений.
В отличие от гауссовых исключений алгоритм Холесского численно устойчив без каких-либо перестановок [3].
В силу него существует априорное ограничение сверху на элементы : каждый из них не превосходит максимальную величину.
Соответственно лавинообразный рост элементов невозможен независимо от того, будут ведущие элементы малыми или нет.
Во-первых, для знаконеопределенной матрицы факторизация Холесского может не существовать.
Во-вторых, даже если она и существует, то гарантировать численную устойчивость алгоритма уже нельзя, поскольку никаких априорных ограничений на субдиагональные элементы в рассматриваемом случае не будет.
Итак, на основе обычной факторизации Холесского построение не получить, для этого нужно воспользоваться модифицированной факторизацией.
Наиболее эффективная вычислительная схема предложена в [2, 3].
Данный подход состоит в том, чтобы строить факторы Холесского и, подчиняющиеся двум требованиям: все диагональные элементы должны быть существенно положительными, модули всех элементов треугольного фактора должны быть равномерно ограничены сверху.
Для сохранения численной устойчивости процедуры построения, а также для совпадения и в случае положительно определенной целесообразно величину вычислять по формуле max, / 1,.
Здесь максимальный модуль недиагонального элемента ; значение максимального из диагональных элементов ; машинная точность; вводится в формулу расчета, чтобы обеспечить устойчивость вычислений, когда норма очень мала [4].
При этом процедура расчета модифицированных факторов и фактически представляет собой обычный алгоритм факторизации Холесского с попутным увеличением  диагонали исходной матрицы с целью добиться выполнения неравенств .
Таким образом, положительно определенная матрица может отличаться от исходной матрицы только диагональными элементами.
Для построения модифицированного разложения Холесского требуется выполнить около арифметических операций, примерно столько же, сколько необходимо для обычного разложения для положительно определенной матрицы.
Дана наиболее эффективная схема организации расчетов.
В процессе вычисленияэлементов).
.
Присвоить индексу столбца значение 1.
.
Найти индекс, такой, что max.
Поменять местами все данные, отвечающие столбцам матрицы с номерами и, а затем проделать то же самое с данными, отвечающими еестрокам.
.
.
Вычислить max, , / и поправку.
.
Присвоить значение + 1 и вернуться к шагу 2.
Подход к увеличению эффективности алгоритма Гилла и Мюррея предложен в [1].
Доказано, что подход к построению направления спуска определяет решение проблемы масштабирования шагов при спуске и интеграцию с методом доверительной окрестности следующим образом.
Величина элементов зависит от способа задания направления спуска.
Это может стать ключом к решению проблемы масштабирования шагов при спуске, но такое предположение ошибочно: подход линейной алгебры к вычислению направления спуска исключает расчет элементов вектора по ходу построения модифицированного разложения Холесского [5, 6].
Нужен альтернативный подход, который опишем следующим образом.
В скалярной форме это равенство выглядит следующим образом:.
Интеграция техники исключения Гаусса и факторизации Холесского генерирует множество реализаций численно устойчивых вычислительных схем задания направления спуска, в основе которых лежит требование, чтобы на очередном шаге вычислений коэффициентов факторов Холесского соответствующий диагональный элемент матрицы и соответствующий элемент вектора сначала рассчитывались по вычисленным ранее значениям этих коэффициентов.
Затем диагональный элемент увеличивается настолько, насколько необходимо, чтобы все диагональные элементы были существенно положительными, модули всех элементов и были равномерно ограничены сверху.
 Интеграция техники исключения Гаусса и факторизации Холесского генерирует множество реализаций вычислительных схем интеграции с методом доверительной окрестности, например, следующим образом.
 Здесь параметр задается пользователем, число  характеризует степень однородности, при этом  простейшая форма аппроксимации, отличная от квадратичной.
Пусть, где диагональная матрица с элементами на диагонали.
Тогда, что означает сдвиг на всехматрицы.
В методах с регулировкой шага матрицу модифицируют так, чтобы изменения не затрагивали подпространства, натянутого на ее собственные векторы с положительными собственными значениями [3].
Из вышесказанного следует, что стратегия выбора направления спуска определяет и интеграцию с методом доверительной окрестности.
Все фигурирующие в ней величины при реализации на ЭВМ могут размещаться в памяти, первоначально выделяемой для записи матриц и.
При этом коэффициенты рассчитываемых факторов занимают места ее использованных элементов.
В процессе вычисления.
Положить,.
Найти такой индекс, что max, и поменять местами все данные, отвечающие строкам матрицы с номерами и, а затем проделать то же самое с данными, отвечающими еестолбцам.
Если, то положить ; иначе положить.
Если, то перейти к шагу 8; иначе перейти к шагу 6.
Если, то перейти к шагу 8; иначе перейти к шагу 7.
Вычислить / .
В основе лежит интеграция подходов [3, 1012].
Предложенный подход к модификации критериев останова, разработанных Гиллом, Мюрреем и Райт [3], можно найти в [6].
Предложенный подход к оцениванию конечноразностных интервалов и подход к конечно-разностной аппроксимации первых и вторых производных можно найти в [1].
В основе лежит интеграция подходов [3, 11], там же описаны способы выбора конечно-разностных интервалов.
Стандартные программы численного дифференцирования нацелены на поиск конечно-разностного интервала, обеспечивающего минимальную суммарную ошибку вычисляемого приближения.
Алгоритмы выбора интервала для центральной конечно-разностной формулы можно найти, например, в [13].
Однако для оптимизационных приложений такие программы не подходят, так как, обеспечивая избыточную точность вычисления оценок производных, они обычно требуют слишком большого числа обращений к процедуре расчета значений функции.
В [14] отмечено, что замена градиентов их конечно-разностными оценками лучше всего проходит в квазиньютоновских методах.
Для методов ньютоновского типа результаты получаются менее удовлетворительными.
Алгоритмы безусловной оптимизации должны быть протестированы по крайней мере в двух различных смыслах: для оценки конкретной реализации и соответствующих вычислительных процедур; очевидно, что хорошо разработанные тестовые задачи являются очень мощным инструментом для уточнения концепций и механизмов алгоритма; для получения представления о гипотезе, доказательства работоспособности алгоритма и сравнения алгоритмов на экспериментальном уровне.
Как правило, задачи безусловной оптимизации можно разделить на два типа: искусственные и реальные.
Искусственные задачи используются для того, чтобы увидеть поведение алгоритма в различных трудных ситуациях, таких как оптимизация функций с длинными узкими оврагами, со значительными нуль-пространственными эффектами, унимодальных, с огромным числом существенных локальных экстремумов и т.д.
Основной характеристикой искусственных задач является то, что их относительно легко настраивать и применять в процессе построения алгоритма.
Реальные задачи берутся из разных источников прикладных оптимизационных задач физики, химии, техники, биологии, экономики, океанологии, астрономии, метеорологии и т.д.
В отличие от искусственных настройки реальных задач труднодоступны и ими нелегко оперировать.
Они могут иметь сложные алгебраические или дифференциальные выражения, могут зависеть от огромного количества данных и, возможно, зависят от некоторых параметров, которые должны быть оценены определенным образом.
Очень хорошая коллекция реальных задач безусловной оптимизации описана в работах [15, 16].
Следует отметить, что собрание коллекций реальных задач началось в конце 1970-х годов с отстаивания высокого качества отчетности о вычислительных экспериментах математического программирования с ПО [1719].
Источником тестовых задач, рассмотренных в данной работе, является коллекция [20], в состав которой вошли тестовые функции из коллекции CUTE и прочих [2124], а также из других работ и технических отчетов.
Цель этой коллекции представить большое количество общих тестовых функций, которые могут использоваться для тестирования алгоритмов безусловной оптимизации и сравнения исследований.
Для каждой функции даны алгебраические представления и начальные  точки.
Для всех задач из коллекции [20] известные алгоритмы безусловной оптимизации, например, квазиньютоновские, сходятся к одному и тому же локальному решению.
Опишем конкретные тестовые задачи [20].
Во-первых, сравнению подвергаются не методы, а машинные реализации соответствующих алгоритмов.
Результат сравнения зависит от качества программного кода, выбора параметров алгоритма, числовых типов данных и т.д.
Во-вторых, неясно, каким образом соизмерять трудоемкость различных методов.
Естественный, на первый взгляд, критерий затраченное машинное время в действительности не подходит: сложно сравнивать быстродействие различных машин, не всегда имеются данные о затратах времени при работе в мультипроцессорном режиме и т.д.
Более надежным показателем является число вычислений минимизируемой функции или другая внутренняя характеристика метода.
Но и здесь возникает ряд проблем.
Например, неясно, как соизмерять трудоемкость вычисления функции и решения различных вспомогательных задач.
Затруднительно сопоставлять вычисления функции и ее производных.
Однако для дискретной задачи оптимального управления градиент лишь примерно вдвое дороже функции [25].
Для квадратичной функции градиент вычисляется даже проще, чем ее значения.
Так же дело обстоит и с субградиентом в минимаксной задаче и т.д.
В-третьих, методы могут по-разному вести себя на разных этапах процесса минимизации.
Более того, поведение разных величин, характеризующих точность решения, может быть также различным.
Никакого удовлетворительного способа преодоления перечисленных трудностей не существует.
Единственное, что можно сделать в подобной ситуации, приводить данные о результатах вычислений в развернутой форме, чтобы иметь возможность сравнения методов по разным критериям.
Рекомендуется при публикации результатов проверки методов придерживаться следующих правил [25]: приводить точную формулировку задачи, для которой проводился счет, включая все ее параметры и начальное приближение; указывать тип ЭВМ и данных, язык и среду программирования, сведения о программе; давать подробное описание применяемого алгоритма или отсылать к его публикации, если она имеется; сообщать различные характеристики точности приближения, невязку в ограничениях и выполнении условий экстремума; в задачах малой размерности приводить и сами приближения; указывать подробные сведения о трудоемкости вычислений.
При выполнении этих условий можно воспроизводить полученные данные и сравнивать их с другими по разным показателям.
Тестовые задачи с известным решением можно построить следующим образом.
Тогда  достигает минимума в точке.
Другой способ связан с выбором функций вида, , ,.
Существуют и другие приемы построения функций с известной точкой минимума.
Например, для задач  эффективен метод ГауссаНьютона [3], для  метод динамического программирования и покоординатного спуска [25].
Найти такой индекс, что max, и поменять местами все данные, отвечающие строкам матрицы с номерами и, а затем проделать то же самое с данными, отвечающими еестолбцам.
Подход Гилла и Мюррея к дополнительному уменьшению нормы поправки развит в [6].
Доказано, что фактическое значение нормы поправки можно дополнительно уменьшить, если использовать симметричные перестановки строк и столбцов.
На очередном,максимальна.
Такая стратегия дает возможность увеличить численную устойчивость расчета элементов, , и остается работоспособной и в том случае, когда не равна нулю, но очень мала.
Рассмотрение предлагаемой формулы вычисления величины, учитывающей такую зависимость, не является целью данной работы и находится в стадии экспериментального сравнения эффективности.
В данной работе величину предлагается вычислять по формуле,  где max, машинная точность; вводится в формулу расчета, чтобы обеспечить устойчивость вычислений, когда норма очень мала.
Применение формулы  хорошо согласуется с численными экспериментами, описанными в данной работе.
Ниже приводится предлагаемая модификация вычислительной схемы 2, дана наиболее эффективная схема организации расчетов.
Положить,.
Найти индекс, такой, что max, и поменять местами все данные, отвечающие строкам матрицы с номерами и, а затем проделать то же самое с данными, отвечающими еестолбцам.
Если, то положить ; иначе положить.
Если, то перейти к шагу 8; иначе перейти к шагу 6.
Если, перейти к шагу 8; иначе перейти к шагу 7.
Вычислить / .
Если, перейти к шагу 11.
В данной работе отмечена взаимосвязь подхода к увеличению эффективности гауссова исключения для разреженных матриц в [26] и предлагаемого подхода к увеличению эффективности численных методов ньютоновского и квазиньютоновского типов использование структуры матрицы, то есть информации о том, в каких позициях матрицы хранятся ненулевые элементы.
Для ньютоновских и квазиньютоновских методов безусловной оптимизации, основанных на факторизации Холесского, с регулировкой шага и с конечно-разностной аппроксимацией первых и вторых производных это возможность уменьшения числа вычислений функции путем формирования матрицы вторых производных в соответствии с ее структурой.
Данное исследование является прямым продолжением работы [14].
NmbmApp отличается от своего классического прототипа Nmbm конечно-разностной аппроксимацией первых и вторых производных.
Все версии алгоритмов реализованы на языке Visual Basic.
NET, среда разработки Microsoft Visual Studio 2010.
Приложение NmbmsApp отличается от своего классического прототипа NmbmApp формированием матрицы вторых производных в соответствии с ее структурой.
NmbmsApp машинная реализация ньютоновских методов оптимизации с регулировкой шага, основанных на факторизации Холесского .
Достоинством подхода, основанного на применении формул численного дифференцирования, кроме его универсальности, является низкая стоимость подготовки задачи к компьютерному моделированию [29].
В то время как результаты численных исследований, приведенные в [14], показывают, что конечно-разностные аналоги проигрывают в точности решения следующих задач оптимизации.
Функция невыпуклая, с искривленным оврагом, обусловленность велика.
Функция имеет несколько локальных минимумов, это обстоятельство может вызвать преждевременное окончание процесса.
В таблице 1 приводятся результаты численных исследований, выполненных в трех версиях предложенного ньютоновского метода безусловной минимизации: Nmbm, NmbmApp [6, 9, 14, 27, 28] и предлагаемой NmbmsApp.
Результаты данного сравнительного исследования позволяют оценить предлагаемую версию ньютоновского метода безусловной оптимизации с регулировкой шага, основанной на факторизации Холесского с конечно-разностной аппроксимацией первых и вторых производных  как более предпочтительную по сравнению с NmbmApp .
Долан и Морэ впервые предложили применение бенчмаркинга в качестве нового инструмента использования статистических данных для сравнения итерационных алгоритмов путем демонстрации профилей производительности [30].
Термин бенчмаркинг англоязычный и не имеет дословного перевода на русский язык, происходит от английских слов bench  и mark .
Это словосочетание трактуется по-разному: опорная отметка, отметка высоты, эталонное сравнение и т.д.
Как правило, термином бенчмаркинг обозначается один из инструментов совершенствования деятельности.
Профилем производительности для метода решения оптимизационной задачи называется функция распределения какого-либо измеримого показателя производительности [30].
Вычисление профилей производительности позволяет визуализировать различия по эффективности нескольких оптимизационных методов, причем для их построения используется отдельная программа [30].
min : Здесь множество сравниваемых методов, множество решаемых с помощью этих методов задач.
Количество элементов в обозначено через, соответственно количество элементов в.
В качестве измеримых показателей производительности, как правило, используются число итераций и число вычислений значений функции  [3133].
В этой технике можно выбрать индекс производительности в качестве меры сравнения среди рассмотренных алгоритмов и проиллюстрировать полученные результаты с помощью профилей производительности.
Бенчмаркинг, как и любой другой инструмент для сравнения итерационных алгоритмов, имеет свои достоинства и недостатки.
Чувствительность только к измеримому показателю производительности и отсутствие удовлетворительного способа сравнения между собой нескольких методов оптимизации по результатам численных экспериментов [25] часто являются причинами разногласий при интерпретации результатов [30].
Кроме того, вычисление профилей производительности требует отбрасывания задач, для которых машинные реализации соответствующих методов потерпели неудачу [30], что усложняет процесс сравнения итерационных алгоритмов.
В данной работе, как и в [3133], все тестовые задачи описаны в [20], все сравниваемые алгоритмы безусловной оптимизации сходятся к одному и тому же локальному решению, сравнению подлежат подходы к заданию направления спуска, результаты решения заносятся в таблицы.
Следует отметить: если объем статистических данных небольшой, то для сравнения итерационных алгоритмов, как правило, достаточно таблиц [32, 33]; иначе для сравнения итерационных алгоритмов используется бенчмаркинг путем демонстрации профилей производительности [30, 31].
В [3133] завершение итераций производится с использованием одного из следующих критериев останова:  соответственно.
Отсюда следует отсутствие статистических данных о точности решения тестовых задач, что является недостатком сравнения итерационных алгоритмов.
Поэтому в данной работе предлагается приводить и статистические данные о решении с максимальной точностью, а не только данные, соответствующие критериям .
Результаты численных исследований приведены в таблицах 2 и 3 соответственно.
Кроме того, доказано, что модифицированная факторизация Холесского оптимизированный алгоритм в том смысле, что параметр подбирается в нем путем минимизации априорной оценки нормы поправки при условии сохранения существенно положительно определенной матрицы неизменной и с очевидностью зависит от способа задания направления спуска [1, 6].
В данной работе доказанные утверждения позволили модифицировать формулу вычисления величины, предложенную в [2], и построить вычислительную схему 3.
Полученные результаты хорошо согласуются с численными экспериментами, приведенными в данной работе.
Изучен подход к увеличению эффективности ньютоновских методов с конечно-разностной аппроксимацией первых и вторых производных.
Подход является основой для дальнейших исследований, результаты которых могут быть использованы для построения численных методов ньютоновского типа.
Рассмотрена взаимосвязь подхода к увеличению эффективности гауссова исключения для разреженных матриц [26] и предлагаемого подхода к увеличению эффективности численных методов ньютоновского типа использование структуры матрицы, то есть информации о том, в каких позициях матрицы хранятся ненулевые элементы.
Для ньютоновских методов безусловной оптимизации, основанных на факторизации Холесского, с регулировкой шага и с конечно-разностной аппроксимацией первых и вторых производных, это возможность уменьшения числа вычислений функции путем формирования матрицы вторых производных в соответствии с ее структурой.
Данное исследование является прямым продолжением работы [14].
