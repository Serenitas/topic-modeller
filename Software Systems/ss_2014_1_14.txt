
При решении практических задач нахождения оптимальных параметров какого-либо процесса или настроек системы требуется соблюдение ряда ограничений, накладываемых на диапазоны их изменения, обусловленные физической природой объекта или экономическими требованиями.
Кроме того, зачастую нельзя с достаточной точностью описать реальную систему без использования алгоритмических выражений, что приводит к невозможности ее оптимизации только математическими методами.
Одним из способов решения таких задач, относящихся к задачам условной оптимизации, является аппарат эволюционных алгоритмов, в частности .
Для этого к ним применяется ряд методов, воздействующих как на итоговое значение целевой функции, отражающей качество найденного решения, так и на состав множества решений, которыми оперирует ГА.
Следовательно, разработка новых, более эффективных методов учета ограничений в эволюционных алгоритмах и решения задач условной оптимизации является актуальной для научных и технических исследований.
В данном методе происходит уменьшение штрафа на следующем шаге, если лучший индивид популяции  на протяжении последних итераций принадлежал допустимой области.
Если же лучший индивид популяции в течение того же промежутка времени выходил за границы допустимой области, происходит увеличение штрафа.
Описанные методы универсальны и подходят для применения в любом ГА без его существенной модификации.
Кроме данного вида методов, воздействующих непосредственно на итоговое значение целевой функции, существует ряд механизмов, влияющих на структуру и порядок работы самого алгоритма для повышения его эффективности при решении задач условной оптимизации [24].
Одним из них является метод поведенческой памяти [5].
Суть его в последовательном увеличении количества критериев, которым будет удовлетворять заданная часть популяции, при итеративной работе генетических операторов поиска.
В работе [6] предлагается новый метод взаимодействия с пространством поиска и способом накопления информации о решении задачи.
Перед описанием предлагаемых модификаций ДАГА для решения задач условной оптимизации приведем его алгоритм, используемый при решении однокритериальных безусловных задач оптимизации.
Задачейрешений.
Вводится параметр, определяющий количество раундов алгоритма, в которых индивид содержался в популяции в неизменном состоянии.
В изначальной случайно сгенерированной популяции выделяются / лучших индивидов, формирующихв.
В каждом раунде алгоритма раз формируется потомок в.
Для этого случайно выбираетсяиз.
Второйфункции.
При ее равных значениях с наибольшим значением.
После определения пары формируется потомок путем скрещивания хромосом и применения оператора мутации.
Далее происходит сравнение по значению по целевой функции потомка и.
Если потомок лучше, то он замещает, а его параметр обнуляется.
Если лучше, то потомок отбрасывается, а увеличивается на 1.
По завершении процедуры формирования потомков изменяется соотношение количества индивидов / по периодическому закону.
Далее осуществляется поиск индивидов для сохранения их генетической информации в нового поколения.
Для этого просматриваем всех индивидов и отбираем тех, у которых время жизни больше значения параметра, установленного пользователем, и наихудшее значение целевой функции.
После этого сравниваем значение пригодности найденного-индивида.
Если унего.
После проверки всех1.
При недостатке индивидов в они добавляются из только по критерию пригодности.
При применении рассмотренных выше методов условной оптимизации к ДАГА были получены два способа его модификаций.
Первый способ предусматривает использование классических схем статических, динамических или адаптивных штрафов.
В этом случае к вычисленному значению целевой функции добавляется некоторая величина, соответствующая степени нарушения заданных ограничений текущим вектором решений.
При таком подходе не требуется доработка самого алгоритма оптимизации и эффективность решения задачи условной оптимизации сводится к выбору правильных коэффициентов штрафных функций.
Второй способ предполагает внесение изменений в сам алгоритм оптимизации.
Поскольку в ДАГА применяется разделение на две субпопуляции, переход между которыми возможен при доказанной в течение нескольких поколений успешности найденного решения, к нему может быть применена идея, заложенная в методе поведенческой памяти [5].
А именно, в субпопуляцию индивиды будут отбираться по следующим параметрам: удовлетворение наибольшему количеству критериев, наибольшее значение параметра.
В то же время к субпопуляции для формирования значений целевых функций могут применяться рассмотренные штрафные функции.
Использовалась генерация начальных популяций множеством допустимых решений.
Общее количество индивидов в субпопуляциях и составляло 100, количество поколений также равнялось 100, использовалось одноточечное и двухточечное скрещивание.
Проводилось исследование штрафных функций отдельно и в сочетании их с модификацией алгоритма.
Оценка эффективности алгоритма производилась по параметрам надежности и скорости поиска решений.
Под надежностью понимается доля запусков из 100, при которых был найден глобальный оптимум функции на интервале, удовлетворяющий заданным ограничениям.
Скорость определяется как усредненный номер поколения, на котором был найден глобальный оптимум.
Результаты исследования эффективности ДАГА при решении однокритериальных задач условной оптимизации на множестве тестовых функций приведены в таблице 2.
Проведем сравнение эффективности ДАГА с результатами исследований из [7] , которые были получены при тех же параметрах тестирования алгоритмов и для тех же функций.
По полученным результатам и их сравнительному анализу с [7] можно сделать следующие выводы: для ДАГА наибольшую эффективность показывает сочетание метода динамического штрафа и модификации алгоритма; сниженная эффективность адаптивных штрафов связана с наличием двух субпопуляций и частого изменения состава подмножества ; при сравнении с классическим ГА можно заключить, что ДАГА лучше усредненного по эффективности классического алгоритма, но может уступать лучшему при неоптимальных настройках; при сравнении с коэволюционным алгоритмом, являющимся также развитием классического ГА, можно сказать, что данные алгоритмы сравнимы по эффективности.
Таким образом, в работе предложен и обоснован новый подход к решению задачи условной оптимизации, основная идея которого заключается в дифференциации и специализации субпопуляций, с целью повышения эффективности  ГА как эволюционирующей системы.
Разработанный алгоритм по эффективности решения задачи условной оптимизации на множестве тестовых данных превосходит классический ГА и сопоставим с коэволюционным алгоритмом.
