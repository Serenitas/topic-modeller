В последнее время среди специалистов по анализу данных и машинному обучению все более популярным становится ПО для организации исследований. Прежде всего это связано с большим количеством этапов обработки данных и спецификой
их выполнения. Можно выделить такую библиотеку, как Sacred , которая позволяет организовать эксперименты без привязки к конкретным моделям, данные параметров моделей и результаты
можно сохранить в БД. В библиотеке Hyperopt 
акцент делается на оптимизации параметров моделей. FGLab  позволяет аналитику запускать свои
модели на распределенной системе с возможностью сохранять результаты экспериментов и их параметры в БД. Для сложных вычислительных задач
с применением Hadoop, которые могут длиться дни
или недели, подойдет Luigi . Данный пакет позволяет организовать управление многочисленными
вычислительными задачами в одном месте. Последние две системы имеют интерфейс для визуализации результатов и информации по задачам.
Заключительным этапом в решении задачи машинного обучения является построение ансамбля
моделей, поскольку в некоторых случаях оптимальное решение может быть получено с применением ансамбля нескольких различных моделей.
Большое количество источников показывают практическую значимость применения ансамбля в решении прикладных задач . Очень часто в таких ансамблях используют нейросетевые модели. Примечательно, что построение ансамбля только
из нейросетевых моделей в некоторых задачах дает
преимущество . В связи с этим возникает
проблема хранения данных на этапах моделирования, в том числе данных самих моделей и построенных с их помощью ансамблей. Проведенный обзор систем организации экспериментов показал,
что существующие системы не решают такую проблему в явном виде.
Цель данной работы – проектирование и разработка системы хранения ансамблей нейросетевых
моделей, обеспечивающей структурированное хранение данных на различных этапах решения задач
прогнозирования временных рядов. Разработка
хранилища позволит не только организовать процесс анализа данных, но и повысить качество результирующих моделей за счет автоматизации процесса формирования ансамблей.
Работу можно разделить на следующие основные части:
 разработка модели данных и архитектуры
системы хранения;
 разработка пользовательского интерфейса;
 тестирование системы на реальных данных.
Для задач прогнозирования временных рядов
принято использовать два типа ИНС: рекуррентные сети (RNN) .
Задержку по времени также можно применять и
для рекуррентных сетей . В работе при решении задачи прогнозирования временного ряда будет использована LSTM (long short-term memory –
долгая краткосрочная память). Рекуррентные
нейронные сети, основанные на этом подходе, получили большое распространение при решении задач распознавания рукописного текста, моделирования языка, машинного перевода, обработки
аудио- и видеоизображений, анализа тональности и
классификации текстов, прогнозирования временных рядов.
При решении сложных задач классификации,
регрессии, а также прогнозирования временных рядов часто оказывается, что ни один из алгоритмов
не обеспечивает желаемого качества восстановления зависимости. В таких случаях имеет смысл
строить композиции алгоритмов (ансамбли), в которых ошибки отдельных алгоритмов взаимно
компенсируются. Для задачи прогнозирования временных рядов подойдут такие подходы, как голосование и cтекинг (stacking). Они подразумевают
формирование ансамбля из моделей, полученных
на одинаковых данных, что подходит для временных рядов, в отличие от бустинга (boosting) и бэггинга (bagging), где для базовых алгоритмов используются разные данные.
Наиболее известные корректирующие операции голосования:
 простое: взвешенное:
 смесь экспертов:
Простое голосование – это лишь частный случай взвешенного голосования, а взвешенное является частным случаем смеси экспертов.
Основная идея стекинга и его разновидности
блендинга заключается в использовании базовых
алгоритмов для получения предсказаний (метапризнаков) и использовании их как признаков для некоторого обобщающего алгоритма (метаалгоритма). Иными словами, основной идеей стекинга
является преобразование исходного пространства
признаков задачи в новое пространство, точками
которого являются предсказания базовых алгоритмов .
Разработка модели данных
и архитектуры системы хранения
Для реализации поставленных задач необходим
следующий набор программных средств: реляционная БД для хранения данных об
объектах и связей между этими объектами;
 нереляционная БД для хранения временных
рядов;
 язык программирования для реализации логики системы хранения;
 сопутствующие программные пакеты, в том
числе реализующие LSTM.
В качестве реляционной СУБД была использована MySQL . Для хранения временных рядов
современное решение – InfluxDB . Для программирования логики хранилища нейросетевых
моделей выбраны Python версии 2.7.11 и следующие свободно распространяемые пакеты:
 numpy (для работы с массивами );
 sklearn (библиотека для анализа данных
);
 cherrypy (библиотека, позволяющая реализовать веб-сервер ).
Среди многочисленных программных реализаций архитектур нейронных сетей, в частности
LSTM, выделим Theano , а также созданную на
ее основе библиотеку Keras . Библиотека Keras
позволяет использовать как Theano, так и TensorFlow  в качестве основы вычислений. Keras
упрощает процесс создания нейронных сетей,
предоставляя для этого специальный конструктор.
В основе любого кода с использованием Keras лежит объект model, который описывает то, в каком
порядке и какие именно слои содержит ваша
нейронная сеть.
Для построения структуры реляционной БД
рассмотрим необходимые сущности и их структуру .
Проект (project) объединяет ряд исследований
над набором данных. В рамках проекта рассматриваются данные из определенного источника (временной ряд, который хранится в InfluxDB). Все
действия по преобразованию данных, построению
моделей или ансамблей производятся в рамках
проекта.
Источник данных (data_source) представляет
собой описание данных в источнике. В рамках хранилища рассматривается основная задача – прогнозирование временных рядов. Соответственно, информация об источнике данных включает такую
информацию, как начало периода, конец периода,
интервал измерений и другие. В связи с тем, что источник данных не фиксирован, то есть данные в
нем могут изменяться, дополняться, удаляться,
необходимо фиксировать состояние источника
данных на момент начала какого-либо исследования или ряда исследований.
Снимок данных (data_snapshot) отражает состояние источника данных на момент времени. Однако сами данные в исходном виде, как правило, не
пригодны для построения качественных моделей,
поэтому необходимо выполнить ряд преобразований. Преобразование данных (data_preparation) показывает способ преобразования данных (снимка
данных), а также сохраняет преобразованные данные для дальнейшего применения. Преобразованные данные по-прежнему являются временным рядом, но для использования в различных нейросетях
должны быть созданы конечные наборы данных в
виде матриц X и Y, объясняющие признаки и целевые значения.
Набор данных (data_set) – это конечная выборка
данных, отвечающая требованиям той или иной
модели. Например, одна модель может использовать для прогнозирования окно в значений, а целевое (прогнозируемое) значение будет отступать
на пункта от окна. В этом случае размерность
матрицы, а формируется по определенному
правилу. При других параметрах выборка будет
сформирована иначе, что и объясняет необходимость введения рассматриваемой сущности.
Снимок данных, преобразование данных и
набор данных – это отдельные наборы данных, пошагово полученные из предыдущего источника.
Эти данные уже необязательно являются временными рядами с точки зрения способа их хранения.
В связи с этим необходимо организовать хранение
этих данных в унифицированном виде. Наиболее
подходящим форматом хранения является CSV
(Comma-Separated Values – разделяемые запятыми
значения) – текстовый формат, предназначенный
для представления табличных данных. Определим
также сущность CSV-данных (data_csv) – это зависимая сущность, которая представляет собой
только сами данные под уникальным идентификатором.
Другим не менее важным набором сущностей
является набор, связанный с нейросетевыми моделями.
Исследование (research) – это группа моделей,
полученных по определенным правилам. Такие
правила устанавливают порядок преобразования
данных, способ построения моделей и их
настройки и т.д. В рамках исследования рассматриваются данные, преобразованные определенным
образом, поэтому все модели, построенные в ходе
исследования, с точки зрения представления работают с одними и теми же данными.
Модель (model) – это представление математической модели. Модель может быть любого типа:
как нейросетевой, так и любой другой (случайный
лес, логистическая регрессия и др.). Для получения
модели данные должны быть подготовлены определенным образом, как говорилось ранее, и сохранены как набор данных. Такой набор и используется далее для обучения и тестирования модели.
В ходе описания настроек или построения модели могут возникать некоторые данные, так или
иначе описывающие модель. Они называются метаданными и требуют вынесения в определенную
сущность (для реляционной БД). Метаданные модели (model_meta) – это простое
представление данных о модели в виде «ключ-значение». Такие данные могут содержать настройки
модели и/или данные о процессе обучения
(ошибка, доля правильных ответов, время обучения, алгоритм обучения и другие).
Последним набором сущностей являются сущности, связанные с ансамблями (комитетами).
Ансамбль (ensemble) – это сущность, создаваемая в рамках одного проекта. Такое ограничение
вводится для ограничения данных: все модели
должны работать на данных одного и того же рода.
Здесь описываются такие данные об ансамбле, как
метод построения ансамбля, тип метамодели (метаклассификатора), математическая модель ансамбля и т.д.
Ансамбль составляется из моделей. При этом
каждая модель может содержать ряд определенных
параметров с точки зрения ансамбля, например, вес
эксперта для линейной регрессии.
Элемент ансамбля (ensemble_item) – параметризованная модель, используемая в построении ансамбля.
Физическая модель данных в MySQL представлена на рисунке 1. Для связи реляционной БД
MySQL и нереляционной InfluxDB необходимо
ввести ряд спецификаций:
 измерение (measurement), содержащее экспортируемую информацию, должно иметь имя
data_source;
 измерение обязательно должно включать тэг
(tag) mysql_id, содержащий идентификатор исходных данных, куда будет произведена привязка;
 тип данных значения (value) должен быть
float-числом с плавающей точкой.
Измерение создается автоматически при добавлении новых данных. Рассмотрим пример добавления данных в необходимое измерение по установленным правилам: data_source,mysql_id=234 value=
=. Такой запрос добавит
в БД InfluxDB запись в необходимое измерение для
источника данных с идентификатором 234. Запись
будет содержать значение и привязку ко времени со значением  (timestamp) – .
Одна из основных задач хранилища – предоставление функционального программного интерфейса для взаимодействия с данными, хранящимися в БД. Поэтому, помимо средств хранения данных (MySQL, InfluxDB), хранилище ансамблей
нейросетевых моделей включает внутреннюю логику, определяющую правила функционирования
системы.
Рассмотрим каждый пакет из представленных
на рисунке 2:
 enstorage (полная библиотека хранилища,
включающая в себя основные модели объектов, отражающие сущности БД (ORM, Object-Relational
Mapping))
 adapter (библиотека, реализующая методы
преобразования данных для дальнейшего использования в моделях);
 enmyadmin (содержит основной функционал
встроенной системы администрирования хранилища).

Отдельным классом, который обязательно должен быть использован перед работой с хранилищем ансамблей нейросетевых моделей, является
Connector (рис. 3). Он осуществляет подключение
к необходимым БД (MySQL и InfluxDB). Все
остальные классы являются компонентами ORM и
реализуют следующие стандартные public (доступные извне) функции:
 delete – удаление связанного с БД объекта;
 save – сохранение (создание или обновление) объекта БД;
 get – статичный метод, возвращающий объект класса, к которому он относится, по указанному
идентификатору записи (id);
 get_list – статичный метод, возвращающий
список объектов класса, в котором вызван, по указанным идентификаторам (ids); если идентификаторы не указаны, возвращается полный список всех
объектов.
С течением времени исходные данные в InfluxDB могут обновляться и пополняться. Для фиксации определенного набора данных необходимо
создать снимок (DataSnapshot).
Снимок создается при помощи метода DataSource.create_snapshot(), который загружает текущее состояние источника на указанный временной
период (DataSource: time_from, time_to). Загрузка
данных выполняется с применением агрегирующей функции, группирующей данные по временному интервалу, – DataSource.time_interval. Сохраненный снимок выступает в роли самостоятельных
данных, которые могут быть использованы для
дальнейших исследований.
Для подготовки данных создается объект
DataPreparation, который обеспечивает хранение
подготовленных данных, а также преобразование
данных DataSnapshot. Создание преобразованных
данных выполняется при помощи метода DataSnapshot.create_preparation(clean_method, transform_method, train_part, valid_part, test_part), где параметрами являются (по порядку) метод заполнения пустых значений, метод преобразования значений,
доля обучающей выборки, доля валидационной выборки, доля тестовой выборки. Подготовка данных
в ручном режиме осуществляется методом
DataPreparation.prepare().
После преобразования данных на их основе может быть создано исследование – Research. При создании модели Research не определяет, с каким
набором работает модель, это задача сервиса, использующего хранилище.

Сервис должен произвести следующие действия:
 создать модель, привязанную к исследованию;
 исходя из типа модели преобразовать нужным адаптером (adapter) данные – DataPreparation.create_set(adapter);
 сообщить модели о созданном наборе данных посредством Model.data_set(created_data_set).
При этом в автоматическом режиме адаптером
будут обработаны преобразованные данные DataPreparation. Данный этап является завершающим
для серии преобразования исходных данных, полученных из DataSource.
Еще одним важным потоком данных является
информация, поступающая в ходе построения моделей и ансамблей. Фиксация таких данных (метаданных) для модели осуществляется методами
Model.meta(key, value). Метаданными могут быть
абсолютно любые данные, описывающие модель.
При построении ансамбля дополнительные параметры фиксируются в свободной форме в EnsembleItem.properties, однако рекомендуется использовать формат JSON.
Особенностью хранилища является то, что хранение объектов конечных реализаций моделей осуществляется благодаря специальному формату.
Данные объектов сериализуются и десериализуются при помощи библиотеки pickle. Такой подход
обеспечивает возможность сохранения и восстановления объектов целиком, тем самым обеспечивая высокий уровень интеграции пакета enstorage с
другими библиотеками. Также, благодаря используемому формату, хранилище может принять не
только нейросетевые модели, но и любые другие.
Однако из-за использования библиотеки pickle существует ограничение на использование этих данных в языках, отличных от Python, так как данные
совместимы только с ним.

Тестирование системы
на реальных данных

Разработка
пользовательского интерфейса

Для тестирования работоспособности хранилища в реальных задачах необходимо реализовать
систему построения ансамблей, а также обучения
моделей. Конструктор ансамблей – это отдельный
функционал, который может быть вынесен в специальный пакет endirector. Данный пакет включает
методы построения ансамбля и использует объекты хранилища из пакета enstorage. Ансамбль
формируется в автоматическом режиме на основе
настроек в Ensemble. Далее приведен пример построения ансамбля из набора моделей, а также применения Conductor для формирования метамодели:

Для упрощения администрирования хранилища
ансамблей нейросетевых решений предусмотрен
пакет enmyadmin, входящий в enstorage. Данный
пакет представляет собой веб-сервер с основными
методами администрирования. Основным шаблоном проектирования веб-приложения является
model-view-controller (MVC, «модель-представление-контроллер»). В роли клиентского приложения
выступает HTML5-JS-приложение, разработанное
с использованием AngularJS . Взаимодействие
клиентского и серверного приложений осуществляется по технологии REST (representational state
transfer – «передача состояния представления»), обеспечивающей независимость серверной части
от клиентского приложения. Фреймворк работает с
HTML, включающим дополнительные пользовательские атрибуты, которые описываются директивами, и связывает ввод-вывод области страницы с
Порядок действий для построения ансамбля, ремоделью, состоящей из объектов JavaScript. Значения этих объектов задаются вручную или извлекаются из статических или динамических 
данных.
На рисунке 5 представлена форма просмотра
информации о проекте. В левой части формы находится фиксированная панель навигации, позволяющая просматривать список
проектов и источников данных для быстрого перехода
к ним. Для поиска необходимого пункта предусмотрен функционал фильтрации. В правой части окна находится область управления, включающая элементы
управления открытым объектом.
Разработаны следующие
формы управления объектами: проект, исследование,
модель, ансамбль, исходные
данные, снимок данных,
преобразованные данные,
набор данных.
Важно отметить, что
благодаря использованию
технологии REST клиентское приложение системы
администрирования может
быть разработано на любой
платформе, поддерживающей взаимодействие по
HTTP-протоколу.
Для оценки качества каждой модели, а также
ансамбля
рассчитаем
среднеквадратическую
ошибку (MSE) на тестовой выборке.
На рисунке 7 видим, что наименьшее значение
ошибки у ансамбля (на графике – out). Так как в качестве метамодели использовалась линейная регрессия (Linear Regression), вес каждой модели
можно оценить в результирующем значении. Данные значения записаны в 
Стоит отметить, что наборы данных различных
моделей могут существенно отличаться друг от
друга. Так, один набор данных может быть получен
с задержкой в 4 значения, а другой – в 10. При этом
объем выборок также будет отличаться. Могут использоваться и другие методы конвертации временного ряда, что делает невозможным однозначное получение результата всех моделей для одних
данных. Решением данной проблемы является
идентификация (id) целевых значений. Таким образом, каждый набор  в DataSet также включает
и id. Благодаря этому можно получить
значения всех моделей для конкретного целевого
значения.
В качестве исходных данных для тестирования
системы использованы данные о солнечной активности за период с января 1700 года по февраль 2015
года, всего 303 значения (рис. 6). Для эксперимента
построим 3 нейронные сети с задержкой в 5, 7, 13
значений. В ходе выполнения итогового скрипта осуществляются следующие действия:
 подключение к хранилищу;
 получение данных о наборе данных;
 создание снимка данных;
 преобразование данных (масштабирование,
выделение тестовой выборки – 30 %);
 создание проекта и исследования;
 создание и инициализация модели;
 обучение моделей;
 создание ансамбля.
Далее приведен код создания модели с
применением библиотеки

Значения весов можно интерпретировать следующим образом: наибольшим весом обладает первая модель (keras-1), небольшую корректировку
вносит третья модель (keras-3), компенсацию оказывает вторая модель (keras-2). На рисунке 8 представлены результаты прогноза, полученные с помощью ансамбля.
Масштабированное значение
Заключение
В ходе выполнения данной работы был создан
прототип системы хранения ансамблей нейросетевых моделей. Проведенный эксперимент по прогнозированию солнечной активности показал, что
ошибка ансамбля нейросетевых моделей ниже
ошибки каждой отдельно взятой нейросетевой модели. Несомненно, для улучшения результатов
прогнозирования необходимы дополнительные
эксперименты и совершенствование ПО.
Разработаны следующие программные решения:
 пакет для языка Python, обеспечивающий
быстрое и упрощенное взаимодействие с БД, реализованный с использованием технологии ORM;
 пакет преобразования временного ряда в конечные выборки, применяемые в моделях;
 интерфейс пользователя в виде HTML-приложения, обеспечивающий наглядное отображение
данных и удобное взаимодействие с хранилищем
ансамблей нейросетевых моделей.
Результаты проделанной работы показывают
перспективность разработанных программных решений и обеспечивают высокую степень интеграции в расширяемые программные продукты на
языке Python.
Исследование выполнено при финансовой поддержке РФФИ, проект.