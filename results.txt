best coeffs: phi theta
all_texts 0.6   -2.5
it_texts 0.6   -2.1
Siberian Journal of Psychology 1.0   -2.0




all_texts:
Sparsity Phi: 0.773 (PLSA) vs. 0.000 (ARTM) vs. 0.000 (LDA)
Sparsity Theta: 0.000 (PLSA) vs. 0.810 (ARTM) vs. 0.000 (LDA)
Kernel contrast: 0.768 (PLSA) vs. 0.661 (ARTM)
Kernel purity: 0.254 (PLSA) vs. 0.244 (ARTM)
Kernel size: 640.067 (PLSA) vs. 629.767 (ARTM)
Coherence: 0.000 (PLSA) vs. 0.000 (ARTM)
Background tokens ratio: 0.555 (PLSA) vs. 0.992 (ARTM)
Class precision: 0.000 of 0.000 errors (PLSA) vs. 0.000 of 0.000 errors (ARTM)
Topic mass phi - mass: {'topic_0': 1.0000005960464478, 'topic_1': 1.0000016689300537, 'topic_2': 1.0000009536743164, 'topic_3': 1.0000008344650269, 'topic_4': 0.9999991059303284, 'topic_5': 1.0000014305114746, 'topic_6': 0.9999994039535522, 'topic_7': 0.9999979734420776, 'topic_8': 0.9999988675117493, 'topic_9': 1.000001311302185, 'topic_10': 1.0000005960464478, 'topic_11': 1.0000003576278687, 'topic_12': 1.0000003576278687, 'topic_13': 0.9999998211860657, 'topic_14': 1.0000001192092896, 'topic_15': 1.000000238418579, 'topic_16': 1.0000014305114746, 'topic_17': 0.9999976754188538, 'topic_18': 1.0000004768371582, 'topic_19': 0.9999976754188538, 'topic_20': 1.000001311302185, 'topic_21': 1.0000015497207642, 'topic_22': 0.9999996423721313, 'topic_23': 1.0000007152557373, 'topic_24': 0.9999987483024597, 'topic_25': 0.9999999403953552, 'topic_26': 1.0000028610229492, 'topic_27': 0.9999964237213135, 'topic_28': 1.0000004768371582, 'topic_29': 1.0000004768371582} {'topic_0': 1.0000789165496826, 'topic_1': 1.000124216079712, 'topic_2': 1.0000303983688354, 'topic_3': 1.0000299215316772, 'topic_4': 1.0001035928726196, 'topic_5': 1.000153660774231, 'topic_6': 1.000025749206543, 'topic_7': 1.0001646280288696, 'topic_8': 1.000099539756775, 'topic_9': 1.0001126527786255, 'topic_10': 1.0001473426818848, 'topic_11': 1.0000168085098267, 'topic_12': 1.0000132322311401, 'topic_13': 1.0000107288360596, 'topic_14': 1.000031590461731, 'topic_15': 1.0000730752944946, 'topic_16': 1.0000760555267334, 'topic_17': 1.0001085996627808, 'topic_18': 1.0000261068344116, 'topic_19': 1.0000163316726685, 'topic_20': 0.999987006187439, 'topic_21': 1.0001734495162964, 'topic_22': 1.0000303983688354, 'topic_23': 1.0000207424163818, 'topic_24': 0.9999955296516418, 'topic_25': 1.0001791715621948, 'topic_26': 1.00010085105896, 'topic_27': 1.0000114440917969, 'topic_28': 1.0000874996185303, 'topic_29': 1.0000112056732178}
Topic mass phi - ratio: {'topic_0': 0.03333333879709244, 'topic_1': 0.033333372324705124, 'topic_2': 0.03333334997296333, 'topic_3': 0.033333346247673035, 'topic_4': 0.03333328664302826, 'topic_5': 0.03333336487412453, 'topic_6': 0.033333297818899155, 'topic_7': 0.033333249390125275, 'topic_8': 0.03333327919244766, 'topic_9': 0.03333336114883423, 'topic_10': 0.03333333879709244, 'topic_11': 0.03333332762122154, 'topic_12': 0.03333332762122154, 'topic_13': 0.03333331272006035, 'topic_14': 0.033333320170640945, 'topic_15': 0.033333323895931244, 'topic_16': 0.03333336487412453, 'topic_17': 0.03333323821425438, 'topic_18': 0.03333333134651184, 'topic_19': 0.03333323821425438, 'topic_20': 0.03333336114883423, 'topic_21': 0.033333368599414825, 'topic_22': 0.03333330526947975, 'topic_23': 0.033333342522382736, 'topic_24': 0.033333275467157364, 'topic_25': 0.03333331644535065, 'topic_26': 0.03333341330289841, 'topic_27': 0.033333197236061096, 'topic_28': 0.03333333134651184, 'topic_29': 0.03333333134651184} {'topic_0': 0.03333356976509094, 'topic_1': 0.03333508223295212, 'topic_2': 0.03333195298910141, 'topic_3': 0.033331938087940216, 'topic_4': 0.0333343930542469, 'topic_5': 0.03333606198430061, 'topic_6': 0.03333180025219917, 'topic_7': 0.03333642706274986, 'topic_8': 0.03333425894379616, 'topic_9': 0.03333469480276108, 'topic_10': 0.0333358533680439, 'topic_11': 0.033331502228975296, 'topic_12': 0.033331383019685745, 'topic_13': 0.03333129733800888, 'topic_14': 0.03333199396729469, 'topic_15': 0.03333337604999542, 'topic_16': 0.03333347663283348, 'topic_17': 0.03333456069231033, 'topic_18': 0.03333181142807007, 'topic_19': 0.033331483602523804, 'topic_20': 0.03333050757646561, 'topic_21': 0.03333672136068344, 'topic_22': 0.03333195298910141, 'topic_23': 0.03333163261413574, 'topic_24': 0.03333079069852829, 'topic_25': 0.03333691135048866, 'topic_26': 0.03333430364727974, 'topic_27': 0.03333132341504097, 'topic_28': 0.033333856612443924, 'topic_29': 0.03333131596446037}
Perplexity: 996.936 (PLSA) vs. 1007.202 (ARTM) vs. 1022.893 (LDA)



ARTM training
Sparsity Phi: 0.880 (PLSA) vs. 0.000 (ARTM) vs. 0.000 (LDA)
Sparsity Theta: 0.000 (PLSA) vs. 0.830 (ARTM) vs. 0.000 (LDA)
Kernel contrast: 0.772 (PLSA) vs. 0.663 (ARTM)
Kernel purity: 0.252 (PLSA) vs. 0.244 (ARTM)
Kernel size: 638.900 (PLSA) vs. 631.300 (ARTM)
Coherence: 0.000 (PLSA) vs. 0.000 (ARTM)
Background tokens ratio: 0.020 (PLSA) vs. 0.993 (ARTM)
Class precision: 0.000 of 0.000 errors (PLSA) vs. 0.000 of 0.000 errors (ARTM)
Topic mass phi - mass:
{'topic_0': 0.9999974966049194, 'topic_1': 0.9999988675117493, 'topic_2': 1.0000052452087402, 'topic_3': 1.0000079870224, 'topic_4': 0.9999916553497314, 'topic_5': 1.0000017881393433, 'topic_6': 1.000002145767212, 'topic_7': 1.000003457069397, 'topic_8': 0.9999920725822449, 'topic_9': 0.9999867677688599, 'topic_10': 0.9999967813491821, 'topic_11': 1.0000033378601074, 'topic_12': 1.0000015497207642, 'topic_13': 0.9999996423721313, 'topic_14': 1.0000032186508179, 'topic_15': 1.0000016689300537, 'topic_16': 0.9999986290931702, 'topic_17': 1.0000014305114746, 'topic_18': 1.0000009536743164, 'topic_19': 0.9999956488609314, 'topic_20': 1.0000017881393433, 'topic_21': 0.9999977350234985, 'topic_22': 1.000004768371582, 'topic_23': 0.9999954104423523, 'topic_24': 1.0000042915344238, 'topic_25': 0.9999993443489075, 'topic_26': 0.9999949932098389, 'topic_27': 0.9999793171882629, 'topic_28': 1.0000029802322388, 'topic_29': 1.000004768371582}
{'topic_0': 1.0003345012664795, 'topic_1': 1.0004994869232178, 'topic_2': 1.0004621744155884, 'topic_3': 1.000586748123169, 'topic_4': 1.000295639038086, 'topic_5': 1.0004390478134155, 'topic_6': 1.0001596212387085, 'topic_7': 1.0004165172576904, 'topic_8': 1.00001060962677, 'topic_9': 1.0001760721206665, 'topic_10': 1.0005171298980713, 'topic_11': 1.0006341934204102, 'topic_12': 1.000035285949707, 'topic_13': 1.0001314878463745, 'topic_14': 1.0004513263702393, 'topic_15': 0.9999861121177673, 'topic_16': 1.0006215572357178, 'topic_17': 1.0001227855682373, 'topic_18': 1.000181794166565, 'topic_19': 1.0004290342330933, 'topic_20': 1.0006927251815796, 'topic_21': 1.0000381469726562, 'topic_22': 1.0006730556488037, 'topic_23': 1.0006035566329956, 'topic_24': 1.000011682510376, 'topic_25': 1.000164270401001, 'topic_26': 1.0004668235778809, 'topic_27': 0.9998820424079895, 'topic_28': 1.000477910041809, 'topic_29': 1.0003596544265747}
Topic mass phi - ratio:
{'topic_0': 0.033333249390125275, 'topic_1': 0.033333294093608856, 'topic_2': 0.03333350643515587, 'topic_3': 0.03333359956741333, 'topic_4': 0.033333051949739456, 'topic_5': 0.033333390951156616, 'topic_6': 0.03333340212702751, 'topic_7': 0.03333344683051109, 'topic_8': 0.03333306685090065, 'topic_9': 0.03333289176225662, 'topic_10': 0.033333223313093185, 'topic_11': 0.033333443105220795, 'topic_12': 0.03333338350057602, 'topic_13': 0.033333320170640945, 'topic_14': 0.033333439379930496, 'topic_15': 0.03333338722586632, 'topic_16': 0.03333328664302826, 'topic_17': 0.03333337977528572, 'topic_18': 0.03333336487412453, 'topic_19': 0.0333331860601902, 'topic_20': 0.033333390951156616, 'topic_21': 0.03333325684070587, 'topic_22': 0.033333491533994675, 'topic_23': 0.033333178609609604, 'topic_24': 0.03333347663283348, 'topic_25': 0.03333330899477005, 'topic_26': 0.03333316370844841, 'topic_27': 0.033332642167806625, 'topic_28': 0.0333334319293499, 'topic_29': 0.033333491533994675}
{'topic_0': 0.03333491086959839, 'topic_1': 0.03334040939807892, 'topic_2': 0.03333916515111923, 'topic_3': 0.03334331512451172, 'topic_4': 0.033333614468574524, 'topic_5': 0.03333839401602745, 'topic_6': 0.033329084515571594, 'topic_7': 0.03333764523267746, 'topic_8': 0.033324118703603745, 'topic_9': 0.03332963213324547, 'topic_10': 0.033340997993946075, 'topic_11': 0.033344898372888565, 'topic_12': 0.033324938267469406, 'topic_13': 0.03332814574241638, 'topic_14': 0.03333880379796028, 'topic_15': 0.03332329913973808, 'topic_16': 0.03334447741508484, 'topic_17': 0.0333278551697731, 'topic_18': 0.03332982212305069, 'topic_19': 0.03333805873990059, 'topic_20': 0.03334684669971466, 'topic_21': 0.033325035125017166, 'topic_22': 0.03334619104862213, 'topic_23': 0.033343877643346786, 'topic_24': 0.03332415223121643, 'topic_25': 0.03332923725247383, 'topic_26': 0.03333932161331177, 'topic_27': 0.03331983461976051, 'topic_28': 0.033339690417051315, 'topic_29': 0.03333574905991554}
Perplexity: 979.981 (PLSA) vs. 977.418 (ARTM) vs. 995.249 (LDA)



